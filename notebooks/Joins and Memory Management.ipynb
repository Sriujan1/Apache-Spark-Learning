{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "072372b6-ee0f-4ee8-aa85-5bc4a68277e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "Exception occurred during processing of request from ('127.0.0.1', 55840)\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\sriuj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 316, in _handle_request_noblock\n",
      "    self.process_request(request, client_address)\n",
      "  File \"C:\\Users\\sriuj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 347, in process_request\n",
      "    self.finish_request(request, client_address)\n",
      "  File \"C:\\Users\\sriuj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 360, in finish_request\n",
      "    self.RequestHandlerClass(request, client_address, self)\n",
      "  File \"C:\\Users\\sriuj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socketserver.py\", line 747, in __init__\n",
      "    self.handle()\n",
      "  File \"C:\\Users\\sriuj\\Masters\\MS in Data Science\\Data Engineering\\Pyspark\\spark\\lib\\site-packages\\pyspark\\accumulators.py\", line 295, in handle\n",
      "    poll(accum_updates)\n",
      "  File \"C:\\Users\\sriuj\\Masters\\MS in Data Science\\Data Engineering\\Pyspark\\spark\\lib\\site-packages\\pyspark\\accumulators.py\", line 267, in poll\n",
      "    if self.rfile in r and func():\n",
      "  File \"C:\\Users\\sriuj\\Masters\\MS in Data Science\\Data Engineering\\Pyspark\\spark\\lib\\site-packages\\pyspark\\accumulators.py\", line 271, in accum_updates\n",
      "    num_updates = read_int(self.rfile)\n",
      "  File \"C:\\Users\\sriuj\\Masters\\MS in Data Science\\Data Engineering\\Pyspark\\spark\\lib\\site-packages\\pyspark\\serializers.py\", line 594, in read_int\n",
      "    length = stream.read(4)\n",
      "  File \"C:\\Users\\sriuj\\AppData\\Local\\Programs\\Python\\Python310\\lib\\socket.py\", line 705, in readinto\n",
      "    return self._sock.recv_into(b)\n",
      "ConnectionResetError: [WinError 10054] An existing connection was forcibly closed by the remote host\n",
      "----------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import spark_env\n",
    "\n",
    "spark = spark_env.create_spark_session('joins')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d9697cc4-4dbc-46b8-9f5a-9e0f3dd70005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da7c165-6a51-4d34-ba5a-0871e6821b50",
   "metadata": {},
   "source": [
    "- In Spark, joins are not just about matching keys — they’re executed using different physical strategies under the hood based on data size, memory, and join type.\n",
    "- The most efficient join is the **Broadcast Hash Join**, which works by broadcasting the smaller DataFrame to all executor nodes. This avoids shuffling altogether and allows each executor to perform the join locally. It’s ideal when one side of the join is small enough to fit into memory (typically under 10MB by default, configurable via spark.sql.autoBroadcastJoinThreshold). You can also explicitly use it with broadcast(df_small) when joining with a large DataFrame.\n",
    "- When the data is too large to broadcast but still one side is significantly smaller, Spark may use a **Shuffle Hash Join**. This strategy involves shuffling both datasets based on the join key, and then building a hash table on one side for lookup. It's faster than Sort-Merge Join when memory is sufficient and the key distribution isn’t skewed. However, it's more sensitive to memory pressure and hash collisions and can result in spilling to disk.\n",
    "- For large-scale joins where both DataFrames are big and neither can be broadcasted, Spark uses the **Sort-Merge Join**. This strategy sorts both sides of the data on the join key and then merges them. Though it involves full shuffling and sorting, it’s the most stable and scalable approach for large joins. It’s the default choice for equi-joins when data size exceeds the broadcast threshold and there's no major skew."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55150cf3-09b4-41ea-be3b-6187a4a9f2f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set('spark.sql.autoBroadcastJoinThreshold',-1)\n",
    "spark.conf.set('spark.sql.adaptive.enabled',False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b926ea9d-5209-4742-8d26-a0a3335e8abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = [\n",
    "    (1,\"Alice\"),\n",
    "    (2,\"Bob\"),\n",
    "    (3,\"Charlie\"),\n",
    "    (4,\"David\"),\n",
    "    (5,\"Eva\")\n",
    "]\n",
    "df1 = spark.createDataFrame(data1, [\"id\",\"name\"])\n",
    "\n",
    "data2 = [\n",
    "    (1,50000),\n",
    "    (2,60000),\n",
    "    (3,70000),\n",
    "    (6,80000)\n",
    "]\n",
    "df2 = spark.createDataFrame(data2, [\"id\",\"salary\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6dda383f-f6a5-4515-a76d-e8003ce5fc1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Left Join\n",
    "df_left_join = df1.join(df2,df1['id'] == df2['id'],'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7c5e65b7-7ce6-41cb-a000-7879b0581bd5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+-------+----+------+\n",
      "| id|   name|  id|salary|\n",
      "+---+-------+----+------+\n",
      "|  5|    Eva|NULL|  NULL|\n",
      "|  1|  Alice|   1| 50000|\n",
      "|  3|Charlie|   3| 70000|\n",
      "|  2|    Bob|   2| 60000|\n",
      "|  4|  David|NULL|  NULL|\n",
      "+---+-------+----+------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df_left_join.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd6f820-ddde-4798-a3c8-68bf07654063",
   "metadata": {},
   "source": [
    "## Driver Memory Management\n",
    "\n",
    "- The Driver in Spark is the master process that coordinates all tasks.\n",
    "- It holds metadata, task scheduling information, DAGs and more.\n",
    "- Driver Memory -> Memory allocated to the Driver process when the spark job runs\n",
    "- If Driver runs out of memory -> job fails with OutOfMemoryError\n",
    "- The Driver memory is divided into two memory types\n",
    "1. **JVM Heap Memory**: This is the main memory allocated to the Java Virtual Machine where Spark’s core data structures live (e.g., RDDs, DataFrames, metadata). It is used for Task scheduling, Query planning and optimization, Caching metadata, broadcast variables, etc. JVM heap memory is where Spark runs its logic.\n",
    "2. **OverHead Memory**: This is extra memory reserved outside the JVM heap. It is used for Native memory (like PySpark or Pandas UDFs), Thread stacks, Internal buffers, Memory management by the OS. Overhead memory prevents out-of-memory errors during native or I/O-heavy operations. If you’re using PySpark or UDFs, increasing overhead memory is often necessary. This is max(10% of JVM Heap Memory, 384 MB)\n",
    "\n",
    "#### Driver Out of Memory\n",
    "When the size of the output from executors goes out of the range of the driver memory we get this error. We can mitigate this by avoiding heavy functions that return too much data like df.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c3a461-21ee-4eb0-b161-462005572e42",
   "metadata": {},
   "source": [
    "## Executor Memory Management\n",
    "\n",
    "- The Executor Memory management is broadly divided into four categories:\n",
    "1. JVM Heap Memory: This memory is further broken down into three memories  \n",
    "   a. **Reserved Memory** [300 MB]: Is allocated 300 MB by default  \n",
    "   b. **User Memory** [0.4*(Total memory - Reserved Memory)]: This stores all the user defined functions.  \n",
    "   c. **Spark Memory Pool** [0.6*(Total memory - Reserved Memory)]:\n",
    "   - This memory stores all the cache and transformations that are required.\n",
    "   - 50% memory is used for caching and storing (Long Term Memory). Also called as **Storage Memory**\n",
    "   - 50% memory is used for transformations (Short Term Memory). Also called as **Executor Memory**\n",
    "   - However, this partition can be changed. This is called as allocation and borrowing\n",
    "   - Executor Memory can eliminate storage memory using LRU method but storage memory cannot eliminate the executor memory  \n",
    "3. Off-Heap Memory: Managed by the user and the default is zero\n",
    "4. Overhead Memory: This is extra memory outside the JVM heap memory -> max(10% of executor memory, 384 MB)\n",
    "5. Pyspark Momory: Used rarely and default is zero\n",
    "\n",
    "\n",
    "#### Executor Out of Memory\n",
    "This is caused because of one of the following:\n",
    "- **Large data per task (partition too big):** A single task processes more data than the executor can hold.\n",
    "- **Skewed data in joins or aggregations:** One key has too much data → some executors do all the work and crash.\n",
    "- **Improper caching/persisting:** Caching a large DataFrame without enough memory (especially with MEMORY_ONLY) leads to eviction or OOM.\n",
    "- **Use of wide transformations:** Operations like groupByKey, join, sort cause shuffle and large intermediate data in memory.\n",
    "- **Calling collect() on large DataFrames:** Tries to bring all data to the driver or executor memory → instant crash if it can't fit.\n",
    "- **Heavy PySpark UDFs or Pandas UDFs:** Native code or Python logic consumes off-heap memory → hits memoryOverhead limit.\n",
    "- **Too many tasks per executor:** Multiple tasks run concurrently, each using memory → total usage exceeds limit.\n",
    "- **Improper configuration:** --executor-memory or spark.executor.memoryOverhead is set too low.\n",
    "- **GC overhead without error:** JVM spends too much time in garbage collection due to memory pressure (near-OOM symptom).\n",
    "\n",
    "\n",
    "#### Salting\n",
    "\n",
    "Salting is a technique used in Spark to handle data skew, which occurs when one or a few keys in a join or aggregation operation have significantly more data than others. This imbalance causes Spark to assign a disproportionately large amount of data to a single task or executor, leading to performance bottlenecks or even out-of-memory errors. Salting mitigates this by artificially distributing skewed keys across multiple partitions. It works by appending a random \"salt\" value (like a number) to the skewed key, effectively transforming one heavy key into multiple lighter keys (e.g., \"India\" becomes \"India_1\", \"India_2\", etc.). The other dataset (in the case of a join) is also modified to match this salted structure. After performing the join or aggregation, the results can optionally be de-salted or recombined. This approach helps achieve better parallelism and load balancing during execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9caa14-9c3d-46cb-be22-b7e47e3e1851",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
